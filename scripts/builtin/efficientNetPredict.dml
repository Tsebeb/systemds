#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

# Trains a partial Efficient-Net B0 model
# This script trains the top and bottom part of the Efficient-Net B0
# The original Efficient-Net B0 has the following Layers
#----------------------------------------------------------------
#    Layers                    Dimension      Filters       Nr Repeats
#----------------------------------------------------------------
# 1. Conv3x3                    224x224         32          1
# 2. MBConv1, k3x3              112x112         16          1
# 3. MBConv6, k3x3               56x 56         24          2
# 4. MBConv6, k5x5               28x 28         40          2
# 5. MBConv6, k3x3               14x 14         80          3
# 6. MBConv6, k5x5               14x 14         112         3
# 7. MBConv6, k5x5                7x  7         192         4
# 8. MBConv6, k3x3                7x  7         320         1
# 9. Conv1x1 & Pooling & FC       7x  7         1280        1
#----------------------------------------------------------------
# In this partial implementation we implement the layers number 1, 2 and the prediction layer 9


# Imports
source("nn/layers/affine.dml") as affine
source("nn/layers/conv2d_builtin.dml") as conv2d
source("nn/layers/mbconv.dml") as mbconv
source("nn/layers/global_avg_pool2d.dml") as pool
source("nn/layers/softmax.dml") as softmax

efficientNetPredict = function(matrix[double] X, list[unknown] model, int Cin, int Hin, int Win)
    return(matrix[double] pred)
{
    CW_stem = as.matrix(model[1])
    Cb_stem = as.matrix(model[2])
    Gamma_stem = as.matrix(model[3])
    Beta_stem = as.matrix(model[4])
    EmaMean_stem = as.matrix(model[5])
    EmaVar_stem = as.matrix(model[6])

    MBConv_params = list(as.matrix(model[7]),
                         as.matrix(model[8]),
                         as.matrix(model[9]),
                         as.matrix(model[10]),
                         as.matrix(model[11]),
                         as.matrix(model[12]),
                         as.matrix(model[13]),
                         as.matrix(model[14]),
                         as.matrix(model[15]),
                         as.matrix(model[16]),
                         as.matrix(model[17]),
                         as.matrix(model[18]),
                         as.matrix(model[19]),
                         as.matrix(model[20]),
                         as.matrix(model[21]),
                         as.matrix(model[22]),
                         as.matrix(model[23]),
                         as.matrix(model[24]),
                         as.matrix(model[25]),
                         as.matrix(model[26]),
                         as.matrix(model[27]),
                         as.matrix(model[28]))

    CW_top = as.matrix(model[29])
    Cb_top = as.matrix(model[30])
    Gamma_top = as.matrix(model[31])
    Beta_top = as.matrix(model[32])
    EmaMean_top = as.matrix(model[33])
    EmaVar_top = as.matrix(model[34])
    DW_top = as.matrix(model[35])
    Db_top = as.matrix(model[36])

    padh = (Hin + 1) %% 2
    padw = (Win + 1) %% 2

    [res_out, stem_h, stem_w] = conv2d::forward(X, CW_stem, Cb_stem, Cin, Hin, Win, 3, 3, 2, 2, padh, padw)
    [res_out, None, None, None, None] = batchnorm::forward(res_out, Gamma_stem, Beta_stem, 32, stem_h, stem_w, "test", EmaMean_stem, EmaVar_stem, 0.9, 1e-5)
    res_out = silu::forward(res_out)

    [res_out, None, None, mbconv_h, mbconv_w] = mbconv::forward(res_out, MBConv_params, 32, 16, stem_h, stem_w, 3, 3, 2, 2, padh, padw, FALSE, 1, "test", 0.25)

    [res_out, outh, outw] = conv2d::forward(res_out, CW_top, Cb_top, 16, 1, 1)
    [res_out, None, None, None, None] = batchnorm::forward(res_out, Gamma_top, Beta_top, 1280, outh, outw, "test", EmaMean_top, EmaVar_top, 0.9, 1e-5)
    res_out = silu::forward(res_out)
    [res_out, None, None] = pool::forward(res_out, 1280, outh, outw)
    res_out = affine::forward(res_out, DW_top, Db_top)
    pred = softmax::forward(res_out)
}
